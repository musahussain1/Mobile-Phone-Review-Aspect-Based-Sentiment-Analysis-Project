{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SauTx5b2RLGg"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd_tRk73ROf6"
      },
      "outputs": [],
      "source": [
        "max_records_to_read = 1000000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9IR0yGzRRSJ"
      },
      "source": [
        "# Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e87Y1-xjLn7x",
        "outputId": "f7749882-f7f0-4247-bbc0-54413e7a0e2e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mounting drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Changing directory\n",
        "project_path = '/content/drive/Aspect Based Sentiment Analysis'\n",
        "os.chdir(project_path)\n",
        "\n",
        "print(\"Current working directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uobdzDQPLgmc",
        "outputId": "d55aab59-0c30-4ef5-f56a-0b5062174388"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1000000it [00:17, 58303.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records: 1000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "all_records = []\n",
        "\n",
        "# Opening file\n",
        "file_path = \"Data/Cell_Phones_and_Accessories.jsonl\"\n",
        "with open(file_path, 'r') as fp:\n",
        "\n",
        "    for line in tqdm(fp):\n",
        "\n",
        "      # Checking if max records reached\n",
        "      if len(all_records) >= max_records_to_read:\n",
        "        break\n",
        "      record = json.loads(line.strip())\n",
        "\n",
        "      # Dropping unnecessary information\n",
        "      record.pop(\"images\")\n",
        "      record.pop(\"user_id\")\n",
        "      record.pop(\"asin\")\n",
        "      record.pop(\"parent_asin\")\n",
        "\n",
        "      # Storing record\n",
        "      all_records.append(record)\n",
        "\n",
        "print(f\"Total records: {len(all_records)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ2z26MDNqIL",
        "outputId": "c91c1845-0b6d-4649-e076-9f32a0062175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|    |   rating | title                               | text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |     timestamp |   helpful_vote | verified_purchase   |\n",
            "|---:|---------:|:------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------:|---------------:|:--------------------|\n",
            "|  0 |        4 | No white background! It’s clear!    | I bought this bc I thought it had the nice white background. Turns out it’s clear & since my phone is blue it doesn’t look anything like this.  If I had known that I would have purchased something else. It works ok.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 1612044451196 |              0 | True                |\n",
            "|  1 |        5 | Awesome!  Great price!  Works well! | Perfect. How pissed am I that I recently paid $20 for 1 Fitbit cable and promptly lost the damned thing?  Extremely pissed!  I keep the spare in my medicine bag so hopefully I won’t lose it and my grandson can’t get to it and try to use it as a belt or a dog leash or any of the other nutty things he’s been using the other one for.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | 1534443517349 |              2 | True                |\n",
            "|  2 |        5 | Worked but took an hour to install  | Overall very happy with the end result. If you hate puzzles don’t do it. I love puzzles and it worked for me. Took a lot of concentration and attention to detail and about an hour! The YouTube video helped a ton with installing the new screen. Highly recommend using a how to video when replacing your screen. The tools and supplies they provided were adequate. I did use additional tools from my home to successfully installed a new screen. My screws on the inside of the iPhone were stuck and I had to use an X-Acto knife to get them to come out. The glass Screen for the iPhone was beautiful and worked great. The screen protector that was additional came cracked (Not a big deal as it was extra in my eyes). I did need to use the X-Acto knife to cut off part of a plastic piece to make the final fit. So yes I modified the screen and instructions but ended up working great for me.<br /><br />I was very careful with all of the circuit boards and connections as recommended on the YouTube video. My screen replacement was very successful and I’m very happy with how it turned out. | 1629235304798 |              3 | True                |\n",
            "|  3 |        4 | Decent                              | Lasted about 9 months then the lock button broke off. Decent product but costing scrapes off like crazy.  I shredded this case. Protected my phone tho                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | 1590470082910 |              0 | True                |\n",
            "|  4 |        5 | LOVE IT!                            | LOVE THIS CASE! Works better than my expensive $35 cases! lol                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | 1408994588000 |              0 | True                |\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Converting to a pandas DataFrame\n",
        "df = pd.DataFrame(all_records)\n",
        "print(df.head().to_markdown())\n",
        "\n",
        "# Deleting records list for memory save\n",
        "del(all_records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMjz2LrpOt67",
        "outputId": "84d065ae-2ae0-495b-875b-755e3e7d9220"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000000, 6)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBn5E7HyRrK6",
        "outputId": "073d2cef-ee94-483e-c836-d4639d610484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame saved to Data/loaded_data.csv\n"
          ]
        }
      ],
      "source": [
        "# Saving the DataFrame to a CSV\n",
        "newfile_path = \"Data/loaded_data.csv\"\n",
        "df.to_csv(newfile_path, index=False)\n",
        "print(f\"DataFrame saved to {newfile_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaM1LVnqT2NE"
      },
      "outputs": [],
      "source": [
        "# Checking data types and null values\n",
        "print(df.info())\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "# Statistical summary\n",
        "print(df.describe().to_markdown())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dropping rows with null values\n",
        "df.dropna(subset=['text'], inplace=True)\n",
        "\n",
        "# Converting from milliseconds to seconds\n",
        "df['timestamp'] = df['timestamp'] // 1000\n",
        "\n",
        "# Converting timestamp to datetime\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
        "\n",
        "# Dropping duplicates\n",
        "df.drop_duplicates(subset=['text'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Downloading NLTK resources\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation and special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords and lemmatize\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Preprocessing Text\n",
        "df['cleaned_title'] = df['title'].apply(preprocess_text)\n",
        "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Combining the cleaned title and text\n",
        "df['combined_text'] = df['cleaned_title'] + ' ' + df['cleaned_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dropping NAN if any\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## a) Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Function to calculate sentiment\n",
        "def get_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    polarity = analysis.sentiment.polarity  # Measure the positivity/negativity\n",
        "    if polarity > 0:\n",
        "        return 'positive'\n",
        "    elif polarity < 0:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "# Sentiment\n",
        "df['sentiment'] = df['combined_text'].apply(get_sentiment)\n",
        "print(df[['sentiment', 'combined_text']].head().to_markdown())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sentiment_counts = df['sentiment'].value_counts()\n",
        "\n",
        "# Create the pie chart\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=0, colors=['lightgreen', 'lightcoral', 'skyblue'])\n",
        "plt.title('Sentiment Distribution', fontsize=16)\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Grouping data by sentiment and calculating the mean rating for each sentiment category\n",
        "sentiment_rating = df.groupby('sentiment')['rating'].mean().reset_index()\n",
        "\n",
        "# Plotting average rating for each sentiment\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(data=sentiment_rating, x='sentiment', y='rating', palette='viridis')\n",
        "plt.title('Average Rating by Sentiment', fontsize=16)\n",
        "plt.xlabel('Sentiment', fontsize=12)\n",
        "plt.ylabel('Average Rating', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyzing rating distribution across sentiments\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df, x='sentiment', y='rating', palette='viridis')\n",
        "plt.title('Rating Distribution Across Sentiments', fontsize=16)\n",
        "plt.xlabel('Sentiment', fontsize=12)\n",
        "plt.ylabel('Rating', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze and plot helpful votes by sentiment\n",
        "helpful_votes_sentiment = df.groupby('sentiment')['helpful_vote'].mean().reset_index()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(data=helpful_votes_sentiment, x='sentiment', y='helpful_vote', palette='viridis')\n",
        "plt.title('Average Helpful Votes by Sentiment', fontsize=16)\n",
        "plt.xlabel('Sentiment', fontsize=12)\n",
        "plt.ylabel('Average Helpful Votes', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyze sentiment distribution over time (using year)\n",
        "df['year'] = df['timestamp'].dt.year\n",
        "sentiment_year = df.groupby(['year', 'sentiment']).size().unstack(fill_value=0)\n",
        "\n",
        "sentiment_year.plot(kind='line', figsize=(10, 5), colormap='viridis', marker='o')\n",
        "plt.title('Sentiment Distribution Over Time (Years)', fontsize=16)\n",
        "plt.xlabel('Year', fontsize=12)\n",
        "plt.ylabel('Number of Reviews', fontsize=12)\n",
        "plt.legend(title='Sentiment')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet, sentiwordnet as swn, stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "# Function to get WordNet POS tags\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Filter words based on emotional content\n",
        "def filter_emotional_words(texts):\n",
        "    positive_words = []\n",
        "    negative_words = []\n",
        "    for text in texts:\n",
        "        tokens = word_tokenize(text.lower())\n",
        "        for word, pos_tag in nltk.pos_tag(tokens):\n",
        "            pos = get_wordnet_pos(pos_tag)\n",
        "            if pos:\n",
        "                try:\n",
        "                    synset = swn.senti_synset(f\"{word}.{pos}.01\")\n",
        "                    if synset.obj_score() <= 0.49:  # Filter out neutral/objective words\n",
        "                        if synset.pos_score() > synset.neg_score():\n",
        "                            positive_words.append(word)\n",
        "                        elif synset.neg_score() > synset.pos_score():\n",
        "                            negative_words.append(word)\n",
        "                except:\n",
        "                    pass\n",
        "    return positive_words, negative_words\n",
        "\n",
        "# Separate texts by sentiment\n",
        "sentiment_texts = {\n",
        "    sentiment: df[df['sentiment'] == sentiment]['combined_text'].tolist()\n",
        "    for sentiment in df['sentiment'].unique()\n",
        "}\n",
        "\n",
        "# Prepare word clouds\n",
        "fig, axes = plt.subplots(1, len(sentiment_texts), figsize=(18, 6), sharex=True, sharey=True)\n",
        "\n",
        "for ax, (sentiment, texts) in zip(axes, sentiment_texts.items()):\n",
        "    positive_words, _ = filter_emotional_words(texts)  # Focus on positive words for now\n",
        "    wordcloud = WordCloud(\n",
        "        width=800,\n",
        "        height=400,\n",
        "        background_color='white',\n",
        "        colormap='viridis',\n",
        "        stopwords=set(stopwords.words('english'))\n",
        "    ).generate(' '.join(positive_words))\n",
        "    ax.imshow(wordcloud, interpolation='bilinear')\n",
        "    ax.axis('off')\n",
        "    ax.set_title(f\"Sentiment: {sentiment.capitalize()}\", fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Topic Modeling Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "# BERTopic\n",
        "topic_model = BERTopic(verbose=True, nr_topics=5)\n",
        "topics, probs = topic_model.fit_transform(df['combined_text'])\n",
        "\n",
        "topic_names = {}\n",
        "\n",
        "# Name of the topics\n",
        "for topic_id in range(-1, 4):  # Get 5 topics (0-4)\n",
        "    topic_name = topic_model.get_topic(topic_id)\n",
        "\n",
        "    name = \"\"\n",
        "    for word, prob in topic_name[:3]:\n",
        "      name += word + \" \"\n",
        "    topic_name = name.strip()\n",
        "    topic_names[topic_id] = topic_name\n",
        "\n",
        "# Print the topic names\n",
        "print(topic_names)\n",
        "\n",
        "# Add the topics back to the DataFrame\n",
        "df['Topic'] = topics\n",
        "df['Dominant_Topic'] = df.Topic.map(topic_names)\n",
        "df.drop(columns=['Topic'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize top topics\n",
        "print(\"\\nVisualizing Top Topics...\")\n",
        "topic_model.visualize_barchart(top_n_topics=5).show()\n",
        "\n",
        "# Visualize topic relationships\n",
        "topic_model.visualize_topics().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sentiment Analysis Grouped by Topic\n",
        "sentiment_summary = df.groupby(['Dominant_Topic', 'sentiment']).size().unstack(fill_value=0)\n",
        "\n",
        "print(\"\\nSentiment Summary by Topic:\")\n",
        "print(sentiment_summary.to_markdown())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = sentiment_summary.plot.bar(rot=90, figsize=(8, 6), stacked=True, colormap='viridis')\n",
        "plt.title('Sentiment Distribution by Topics')\n",
        "plt.ylabel('Number of Reviews')\n",
        "plt.xlabel('Topics')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## a) Unbalanced Data Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        ")\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Converting text to numbers using TFIDF\n",
        "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "X = tfidf.fit_transform(df['combined_text']).toarray()\n",
        "y = df['sentiment']\n",
        "\n",
        "# Spliting the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Models to train\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "}\n",
        "\n",
        "# Updated evaluation function with confusion matrix plotting\n",
        "def evaluate_model(name, model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
        "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
        "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Model: {name}\")\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1)\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap='viridis')\n",
        "    plt.title(f'Confusion Matrix for {name}')\n",
        "    plt.show()\n",
        "\n",
        "    return {\"model\": name, \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1_score\": f1}\n",
        "\n",
        "# Train and evaluate all models\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    results.append(evaluate_model(name, model, X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
